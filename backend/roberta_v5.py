# -*- coding: utf-8 -*-
"""roBERTa v5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IUgvwmrNRCYolfBNwKGcgWD-6Pys9vAe
"""

from google.colab import drive
drive.mount('/content/drive')

#!pip install pynvml

import os
import pandas as pd
import torch
from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo

nvmlInit()
h = nvmlDeviceGetHandleByIndex(0)
info = nvmlDeviceGetMemoryInfo(h)
print(f'GPU Memory Used: {info.used / (1024**3):.2f} GB / {info.total / (1024**3):.2f} GB')

tweets = pd.read_csv('/content/drive/MyDrive/2K_tweets_cleaned.csv',
                     encoding='utf8',
                     on_bad_lines='skip',
                     dtype={"text_cleaned_1": str, "text_cleaned_2":str, "text_cleaned_3": str, "f_patient": int})
print(f"Dataset loaded! Shape: {tweets.shape}")

drive_path = "/content/drive/MyDrive/roBERTa_NLP_Results_v5"
os.makedirs(drive_path, exist_ok=True)
print(f"Files will be saved in: {drive_path}")

tweets.head(2)

tweets.columns=['num1', 'index', 'id_user','stream_group','text_orig','f_edpatient','hashtag','text','segmented','text_similar','text_cleaned_1', 'text_cleaned_2','text_cleaned_3']

target_cols=['f_edpatient']

# tweets dataframe'inin tamamını kopyalıyoruz, filtreleme yapmıyoruz
tweets1 = tweets.copy()

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#pd.set_option('display.max_colwidth', None)
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score, precision_score, precision_recall_fscore_support, recall_score
#from simpletransformers.classification import ClassificationModel
import io

df = tweets1.copy()
X_columns = ["text_cleaned_1", "text_cleaned_2", "text_cleaned_3"]
Y = df["f_edpatient"]  # target variable (label)

# clean NaN
for col in X_columns:
    nan_count = df[col].isnull().sum()

    if nan_count > 0:
        print(f"Warning: Detected {nan_count} NaN in {col} column. Cleaning...")
        df = df.dropna(subset=[col])  # delete NaN in that column

datasets = {}

# **Train-Test Split
for col in X_columns:
    X_train, X_test, y_train, y_test = train_test_split(
        df[col], Y.loc[df.index], test_size=0.3, random_state=42, shuffle=True
    )

    datasets[col] = {"X_train": X_train, "X_test": X_test, "y_train": y_train, "y_test": y_test}


print("\n Train-test split completed. The same dataset will be used for all iterations.")

# **assign to variables**
cleaned_datasets = {}

for i, col in enumerate(X_columns, start=1):
    cleaned_datasets[f"X{i}_train"] = datasets[col]["X_train"]
    cleaned_datasets[f"X{i}_test"] = datasets[col]["X_test"]
    cleaned_datasets[f"y{i}_train"] = datasets[col]["y_train"]
    cleaned_datasets[f"y{i}_test"] = datasets[col]["y_test"]

# **Test datat output example**
for col, data in datasets.items():
    print(f"\n **Test data example for {col}:**")
    print(data["X_test"].head())

# **check Y_test distribution**
print("\n Y_test distribution:")
print(datasets["text_cleaned_1"]["y_test"].value_counts(normalize=True))

# **check Train-Test split**
print(f"Train set size: {datasets['text_cleaned_1']['X_train'].shape}")
print(f"Test set size: {datasets['text_cleaned_1']['X_test'].shape}")

# **check NaN **
for col, data in datasets.items():
    nan_count = data["X_train"].isnull().sum().sum()
    print(f"{col} - Number of NaN: {nan_count}")

#!pip install datasets

import gc
import os
import time
import torch
import pandas as pd
import numpy as np
from datasets import Dataset
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback
)
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

os.environ["WANDB_DISABLED"] = "true"

gc.collect()
torch.cuda.empty_cache()

# **Dosya Yolları**
results_path = "/content/drive/MyDrive/NLP_Results_v5"
models_path = "/content/drive/MyDrive/NLP_Models_v5"
os.makedirs(results_path, exist_ok=True)
os.makedirs(models_path, exist_ok=True)

# **Model Parametreleri**
MODEL_NAME = "roberta-base"
N_ITER = 5
NUM_LABELS = 2
LEARNING_RATE = 2e-5
CLEANING_TYPES = ["text_cleaned_1", "text_cleaned_2", "text_cleaned_3"]

# **Tokenizer**
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# **Tokenization**
def encode_examples(batch):
    encoding = tokenizer(
        batch["text"],
        truncation=True,
        padding="max_length",
        max_length=512
    )
    return {
        "input_ids": encoding["input_ids"],
        "attention_mask": encoding["attention_mask"]
    }

# **Metrics**
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    preds = predictions.argmax(axis=1)

    acc = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average="binary")

    return {"accuracy": acc, "precision": precision, "recall": recall, "f1": f1}

# **Training Arguments**
training_args = TrainingArguments(
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=10,
    evaluation_strategy="epoch",
    logging_strategy="epoch",
    save_strategy="epoch",
    learning_rate=LEARNING_RATE,
    logging_dir=f"{results_path}/logs",
    output_dir=models_path,
    overwrite_output_dir=False,
    save_total_limit=None,
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False,
    fp16=True if torch.cuda.is_available() else False,
    weight_decay=0.01,
    save_safetensors=True,
    logging_steps=10,
)

# **CSV için boş dataframe oluştur**
columns = ["Iteration", "Cleaning Type", "Best Epoch", "Training Loss", "Validation Loss", "Accuracy", "Precision", "Recall", "F1", "Model Path"]
results_df = pd.DataFrame(columns=columns)

# **Training Loop - 5 Iteration**
for i in range(N_ITER):
    for clean_type in CLEANING_TYPES:
        print(f"\n **Training {clean_type} - Iter {i}**\n")

        # **Her iterasyonda Torch Seed Rastgele Ayarla**
        torch_seed = np.random.randint(0, 10000)
        torch.manual_seed(torch_seed)
        torch.cuda.manual_seed_all(torch_seed)

        # **Train & Test Data Sabit**
        X_train = datasets[clean_type]["X_train"]
        X_test = datasets[clean_type]["X_test"]
        y_train = datasets[clean_type]["y_train"]
        y_test = datasets[clean_type]["y_test"]

        # **DataFrame oluştur**
        train_df = pd.DataFrame({"text": X_train.tolist(), "label": y_train.astype(int).tolist()})
        test_df = pd.DataFrame({"text": X_test.tolist(), "label": y_test.astype(int).tolist()})

        # **Dataset Formatına Çevir ve Tokenization Yap**
        train_dataset = Dataset.from_pandas(train_df).map(encode_examples, batched=True).remove_columns(["text"])
        test_dataset = Dataset.from_pandas(test_df).map(encode_examples, batched=True).remove_columns(["text"])

        # **Modeli Her Seferinde Random Başlat**
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)
        model.init_weights()

        # **Trainer**
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
        )

        # **Train Model**
        start_time = time.time()
        trainer.train()
        train_time = time.time() - start_time
        print(f"Training Completed in {train_time:.2f} seconds")

        # **En İyi Modeli Seç (Validation Loss + F1 Score)**
        best_epoch = None
        best_loss = float("inf")
        best_f1 = 0.0
        best_metrics = None
        best_train_loss = None

        for log in trainer.state.log_history:
            if "eval_loss" in log and "eval_f1" in log:
                if log["eval_loss"] < best_loss or (log["eval_loss"] == best_loss and log["eval_f1"] > best_f1):
                    best_loss = log["eval_loss"]
                    best_f1 = log["eval_f1"]
                    best_epoch = int(log["epoch"])
                    best_metrics = log
            if "loss" in log:
                best_train_loss = log["loss"]
            elif "train_loss" in log:
                best_train_loss = log["train_loss"]

        # **Eğer hiç `eval_loss` kaydedilmemişse, hata vermeden son logu kullan**
        if best_metrics is None:
            print(f"Warning: No eval_loss found for {clean_type} - Iter {i}, using last recorded values.")
            best_metrics = trainer.state.log_history[-1] if trainer.state.log_history else {}

        # **Modeli Kaydet**
        if best_epoch is not None:
            best_model_path = f"{models_path}/roberta_{clean_type}_best_iter{i}_epoch{best_epoch}"
            os.makedirs(best_model_path, exist_ok=True)
            model.save_pretrained(best_model_path)
            tokenizer.save_pretrained(best_model_path)
            print(f" Best Model Saved to: {best_model_path}")
        else:
            best_model_path = "N/A"

        # **Sonuçları Kaydet**
        new_row = {
            "Iteration": i,
            "Cleaning Type": clean_type,
            "Best Epoch": best_epoch if best_epoch is not None else "N/A",
            "Training Loss": best_train_loss if best_train_loss is not None else "N/A",
            "Validation Loss": best_metrics.get("eval_loss", "N/A"),
            "Accuracy": best_metrics.get("eval_accuracy", "N/A"),
            "Precision": best_metrics.get("eval_precision", "N/A"),
            "Recall": best_metrics.get("eval_recall", "N/A"),
            "F1": best_metrics.get("eval_f1", "N/A"),
            "Model Path": best_model_path
        }
        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)

        # **Modeli temizle**
        del model
        torch.cuda.empty_cache()

csv_results_path = f"{results_path}/roberta_cleaned_results_v5.csv"
results_df.to_csv(csv_results_path, index=False)
print(f"\n Training results saved to: {csv_results_path}")

import pandas as pd
import matplotlib.pyplot as plt

# ✅ NLP_Results_v5.csv dosyasını yükle
results_path = "/content/drive/MyDrive/NLP_Results_v5/roberta_cleaned_results_v5.csv"
results_df = pd.read_csv(results_path)

# ✅ En iyi epoch'u seçtiğimiz için her iterasyonun en iyi değerleri zaten kaydedildi
best_results = results_df.copy()

# ✅ Grafik 1: Best Iteration Performance (F1 Score Comparison)
plt.figure(figsize=(8, 5))
for clean_type in best_results["Cleaning Type"].unique():
    subset = best_results[best_results["Cleaning Type"] == clean_type]
    plt.plot(subset["Iteration"], subset["F1"], marker="o", label=clean_type)

plt.xlabel("Iteration")
plt.ylabel("F1 Score")
plt.title("Best F1 Score by Iteration")
plt.legend()
plt.grid(True)
plt.show()

# ✅ Grafik 2: Cleaning Type Performance (Comparison of Cleaning Types)
plt.figure(figsize=(8, 5))
cleaning_avg = best_results.groupby("Cleaning Type")["F1"].mean()
cleaning_avg.plot(kind="bar", color=["blue", "orange", "green"])

plt.xlabel("Cleaning Type")
plt.ylabel("Average Best F1 Score")
plt.title("Performance by Cleaning Type")
plt.grid(axis="y")
plt.show()

# ✅ Grafik 3: Validation Loss per Iteration (Overfitting Check)
plt.figure(figsize=(8, 5))
for clean_type in best_results["Cleaning Type"].unique():
    subset = best_results[best_results["Cleaning Type"] == clean_type]
    plt.plot(subset["Iteration"], subset["Validation Loss"], marker="s", linestyle="-", label=f"{clean_type}")

plt.xlabel("Iteration")
plt.ylabel("Validation Loss")
plt.title("Validation Loss Across Iterations")
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 🔹 Kaydedilen sonuçları oku
results_path = "/content/drive/MyDrive/NLP_Results_v5/roberta_cleaned_results_v5.csv"
results_df = pd.read_csv(results_path)

# 🔹 Grafik boyutunu ayarla
plt.figure(figsize=(12, 6))

# 🔹 **Her iteration için en iyi modeli tek tek gösterelim**
best_models = results_df.sort_values("Validation Loss")  # En düşük Validation Loss'a göre sırala

# **1️⃣ Validation Loss Karşılaştırması (Düşük Olan Daha İyi)**
plt.subplot(1, 3, 1)
plt.barh(best_models["Cleaning Type"] + " Iter " + best_models["Iteration"].astype(str), best_models["Validation Loss"], color="red")
plt.xlabel("Validation Loss")
plt.title("Best Models - Validation Loss")
plt.grid(axis="x")

# **2️⃣ F1 Score Karşılaştırması (Yüksek Olan Daha İyi)**
plt.subplot(1, 3, 2)
plt.barh(best_models["Cleaning Type"] + " Iter " + best_models["Iteration"].astype(str), best_models["F1"], color="blue")
plt.xlabel("F1 Score")
plt.title("Best Models - F1 Score")
plt.grid(axis="x")

# **3️⃣ Accuracy Karşılaştırması (Yüksek Olan Daha İyi)**
plt.subplot(1, 3, 3)
plt.barh(best_models["Cleaning Type"] + " Iter " + best_models["Iteration"].astype(str), best_models["Accuracy"], color="green")
plt.xlabel("Accuracy")
plt.title("Best Models - Accuracy")
plt.grid(axis="x")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# 🔹 Manuel olarak verilen değerler
epochs = [1, 2, 3, 4, 5]
training_loss = [0.506400, 0.310700, 0.203600, 0.158000, 0.096900]
validation_loss = [0.356910, 0.363017, 0.320547, 0.572378, 0.465878]

# 🔹 Grafik oluştur
plt.figure(figsize=(8, 5))
plt.plot(epochs, training_loss, marker='o', linestyle='-', label="Training Loss", color="blue")
plt.plot(epochs, validation_loss, marker='o', linestyle='-', label="Validation Loss", color="red")

# 🔹 Overfitting başladığı epoch'u vurgula (Epoch 3'ten sonra Validation Loss artıyor)
plt.axvline(x=3, color="gray", linestyle="--", label="Overfitting Begins")

# 🔹 Eksen ve başlıklar
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss (Cleaned 3 - Iter 3)")
plt.legend()
plt.grid(True)

# 🔹 Grafiği göster
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 📂 CSV dosyasını oku
csv_results_path = "/content/drive/MyDrive/NLP_Results_v5/roberta_cleaned_results_v5.csv"
df = pd.read_csv(csv_results_path)

# 🚀 En iyi iterasyonları her temizleme tipi için seç
best_models = df.loc[df.groupby("Cleaning Type")["F1"].idxmax()]  # En yüksek F1 skoruna sahip iterasyonu seç

# 📊 Metrikleri belirle
metrics = ["Accuracy", "Precision", "Recall", "F1", "Validation Loss"]

# 📊 Bar chart için değerleri hazırla
values = {metric: best_models[metric].values for metric in metrics}
clean_types = best_models["Cleaning Type"].values
x = np.arange(len(clean_types))

# 📊 Grafik oluştur
fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.15

# Her metrik için çubukları ekle
for i, metric in enumerate(metrics):
    ax.bar(x + i * bar_width, values[metric], bar_width, label=metric)

# X eksenini temizleme tipleri ile etiketle
ax.set_xticks(x + bar_width)
ax.set_xticklabels(clean_types)

# Başlık ve etiketler
ax.set_title("Comparison of Best Cleaning Types Based on Best Iteration")
ax.set_xlabel("Cleaning Type")
ax.set_ylabel("Score")
ax.legend()

# Grafiği göster
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 📂 CSV dosyasını oku
csv_results_path = "/content/drive/MyDrive/NLP_Results_v5/roberta_cleaned_results_v5.csv"
df = pd.read_csv(csv_results_path)

# 🚀 Her temizleme tipi için 5 iterasyonun ortalamasını al
mean_metrics = df.groupby("Cleaning Type")[["Accuracy", "Precision", "Recall", "F1", "Validation Loss"]].mean()

# 📊 Metrikleri al
metrics = ["Accuracy", "Precision", "Recall", "F1", "Validation Loss"]
clean_types = mean_metrics.index
values = {metric: mean_metrics[metric].values for metric in metrics}
x = np.arange(len(clean_types))

# 📊 Grafik oluştur
fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.15

# Her metrik için çubukları ekle
for i, metric in enumerate(metrics):
    ax.bar(x + i * bar_width, values[metric], bar_width, label=metric)

# X eksenini temizleme tipleri ile etiketle
ax.set_xticks(x + bar_width)
ax.set_xticklabels(clean_types)

# Başlık ve etiketler
ax.set_title("Comparison of Cleaning Types Based on Mean(5) of Iterations")
ax.set_xlabel("Cleaning Type")
ax.set_ylabel("Mean Score")
ax.legend()

# Grafiği göster
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# 📂 CSV dosyasını oku
csv_results_path = "/content/drive/MyDrive/NLP_Results_v5/roberta_cleaned_results_v5.csv"
df = pd.read_csv(csv_results_path)

# 🚀 Her temizleme tipi için 5 iterasyonun ortalamasını al
mean_metrics = df.groupby("Cleaning Type")[["Accuracy", "Precision", "Recall", "F1", "Validation Loss"]].mean()

# 🔹 Cleaning Type sıralamasını 2-1-3 olarak değiştir
sorted_order = ["text_cleaned_2", "text_cleaned_1", "text_cleaned_3"]
mean_metrics = mean_metrics.loc[sorted_order]

## 📊 İlk grafik: Accuracy, Precision, Recall, F1 karşılaştırması ##
plt.figure(figsize=(10, 6))

# Her metriği farklı çizgi ile göster
for metric in ["Accuracy", "Precision", "Recall", "F1"]:
    plt.plot(mean_metrics.index, mean_metrics[metric], marker="o", linestyle="-", label=metric)

# Y ekseni aralığını belirle (0.78 - 0.89 aralığını büyüterek daha net göster)
plt.ylim(0.78, 0.89)

# Grafiği düzenle
plt.title("Metrics Comparison (mean 5 iterations) of Cleaning Types")
plt.xlabel("Cleaning Type")
plt.ylabel("Score")
plt.legend()
plt.grid(True)

# Grafiği göster
plt.show()

## 📊 İkinci grafik: Validation Loss karşılaştırması ##
plt.figure(figsize=(10, 6))

# Validation Loss grafiğini çiz
plt.plot(mean_metrics.index, mean_metrics["Validation Loss"], marker="o", linestyle="-", color="red", label="Validation Loss")

# Y eksenini ölçeklendirerek farkları daha belirgin göster
plt.ylim(mean_metrics["Validation Loss"].min() * 0.95, mean_metrics["Validation Loss"].max() * 1.05)

# Grafiği düzenle
plt.title("Validation Loss Comparison (mean 5 iterations) of Cleaning Types")
plt.xlabel("Cleaning Type")
plt.ylabel("Validation Loss")
plt.legend()
plt.grid(True)

# Grafiği göster
plt.show()

from huggingface_hub import HfApi, login

# 🔹 Hugging Face Token ile giriş yap
login("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")

# 🔹 Hugging Face Kullanıcı Adı
username = "busras"  # Hugging Face kullanıcı adın
repo_name = "roBERTa_ED_Detection"  # **Tek repo içinde saklanacak**
repo_id = f"{username}/{repo_name}"

# Hugging Face API bağlantısı
api = HfApi()
api.create_repo(repo_id, repo_type="model", exist_ok=True)

# 🔹 Model dosyalarının bulunduğu yer (Drive içinde)
base_path = "/content/drive/MyDrive/NLP_Models_v5"

# 🔹 Hugging Face’e Model Yükleme
for clean_type in ["text_cleaned_1", "text_cleaned_2", "text_cleaned_3"]:
    for i in range(5):  # 5 iterasyonun tamamını yükle
        # **Doğru klasörü otomatik bul**
        matching_folders = [f for f in os.listdir(base_path) if f.startswith(f"roberta_{clean_type}_best_iter{i}_epoch")]

        if not matching_folders:
            print(f"{clean_type} Iter {i} not found, skipping...")
            continue

        # **İlgili klasör yolunu oluştur**
        model_path = os.path.join(base_path, matching_folders[0])  # İlk eşleşeni al

        print(f"Uploading {clean_type} Iter {i} from {model_path} to {repo_id}...")

        # 🔹 Hugging Face repo içinde **farklı klasörler** olarak yükleme
        api.upload_folder(
            folder_path=model_path,
            repo_id=repo_id,
            repo_type="model",
            path_in_repo=f"{clean_type}_Iter{i}",  # **Aynı repo içinde farklı klasörler**
            commit_message=f"Uploaded {clean_type} Iter {i} with all files"
        )

        print(f"{clean_type} Iter {i} successfully uploaded into {repo_id}!")

        # Upload işlemi arasında biraz bekleme süresi (Opsiyonel)
        time.sleep(2)

print("All models uploaded successfully to Hugging Face in a single repo!")

from huggingface_hub import login
login("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")