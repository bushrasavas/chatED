# -*- coding: utf-8 -*-
"""roberta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1If5I8wQGaJEnEafe9NUH2Wxi0VLHcGU1
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pynvml

from pynvml import *
nvmlInit()
h = nvmlDeviceGetHandleByIndex(0)
info = nvmlDeviceGetMemoryInfo(h)
print(f'total    : {info.total}')
print(f'free     : {info.free}')
print(f'used     : {info.used}')

import os

drive_path = "/content/drive/MyDrive/NLP_Results"

if not os.path.exists(drive_path):
    os.makedirs(drive_path)

print(f"Files will saved: {drive_path}")

import os
import pandas as pd
import numpy as np
import json
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import re, string, unicodedata
import nltk
from nltk import word_tokenize, sent_tokenize, FreqDist
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer, WordNetLemmatizer

nltk.download('stopwords')
nltk.download('punkt')

# Dosya yolunu güncelledik
tweets = pd.read_csv('/content/drive/MyDrive/2K_tweets_cleaned.csv', encoding='utf8', on_bad_lines='skip')

tweets.head(2)

tweets.columns=['num1', 'index', 'id_user','stream_group','text_orig','f_edpatient','hashtag','text','segmented','text_similar','text_cleaned_1', 'text_cleaned_2','text_cleaned_3']

target_cols=['f_edpatient']

# tweets dataframe'inin tamamını kopyalıyoruz, filtreleme yapmıyoruz
tweets1 = tweets.copy()

!pip install simpletransformers

import pandas as pd
import numpy as np
import spacy
import nltk
import nltk.data
from nltk.tokenize import word_tokenize
from nltk.stem import SnowballStemmer
import regex as re
import string
from collections import defaultdict

import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option('display.max_colwidth', None)

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, accuracy_score

from simpletransformers.classification import ClassificationModel

import io

punctuations = "¡!#$%&'()*+,-./:;<=>¿?@[\]^_`{|}~"

def read_txt(filename):
    words_list = []
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            words_list.append(line.strip())
    return words_list

stopwords = read_txt('/content/drive/MyDrive/english_stopwords.txt')
stemmer = SnowballStemmer('english')

def clean_tweet(tweet, stem=False):
    tweet = tweet.lower().strip()
    tweet = re.sub(r'https?:\/\/\S+', '', tweet)  # URL temizleme
    tweet = re.sub(r'\s([@#][\w_-]+)', "", tweet)  # Mention ve hashtag temizleme
    tweet = re.sub(r"\n", " ", tweet)
    for symbol in punctuations:
        tweet = tweet.replace(symbol, "")
    tokens = [stemmer.stem(token) if stem else token for token in tweet.split() if token not in punctuations and token not in stopwords]
    return " ".join(tokens)

tweets1['text_cleaned_1'] = tweets1['text_orig'].apply(lambda s : clean_tweet(s))  # İlk temizleme yöntemi
tweets1['text_cleaned_2'] = tweets1['text_orig'].apply(lambda s : clean_tweet(s, stem=True))  # İkinci temizleme (Stem kullanarak)
tweets1['text_cleaned_3'] = tweets1['text_orig'].apply(lambda s : clean_tweet(s, stem=False))  # Üçüncü temizleme (Lemmatization olabilir)

print(tweets1[['text_cleaned_1', 'text_cleaned_2', 'text_cleaned_3']].head(5))

"""Farklı text_cleaned sütunlarıyla farklı feature set'ler oluştur

Her biri için aynı f_edpatient hedef değişkeni ile veri setini böl
"""

# Model için kullanılacak verileri seçiyoruz
df = tweets1.copy()
X1 = tweets1['text_cleaned_1']
X2 = tweets1['text_cleaned_2']
X3 = tweets1['text_cleaned_3']
#X = df['text_cleaned']
Y = df['f_edpatient']  # Hedef değişkenimizi tanımlıyoruz

"""Her biri için aynı f_edpatient hedef değişkeni ile veri setini böl"""

# Eğitim ve test setlerine ayırıyoruz
#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
X1_train, X1_test, y_train, y_test = train_test_split(X1, Y, test_size=0.3, random_state=42)
X2_train, X2_test = train_test_split(X2, test_size=0.3, random_state=42)
X3_train, X3_test = train_test_split(X3, test_size=0.3, random_state=42)

''' it might be like this. I did not face with problem because X1, X2 and X3 use same rows, so that y is same for all of them.
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, Y, test_size=0.3, random_state=42)
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, Y, test_size=0.3, random_state=42)
X3_train, X3_test, y3_train, y3_test = train_test_split(X3, Y, test_size=0.3, random_state=42)
'''

print("Y_test distribution:", y_test.value_counts(normalize=True))
print("First 5 samples of X1_test:", X1_test.head())
print("First 5 samples of X2_test:", X2_test.head())
print("First 5 samples of X3_test:", X3_test.head())

train_args = {
    "reprocess_input_data": True,
    "fp16": False,
    "evaluate_during_training": False,
    "evaluate_during_training_verbose": False,
    "learning_rate": 2e-5,
    "train_batch_size": 32,
    "eval_batch_size": 32,
    "num_train_epochs": 10,
    "overwrite_output_dir": True,
    "evaluation_strategy": "epochs"
}

def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average="micro")

def calcule_f1(df):
    return df["tp"] / (df["tp"] + 0.5 * (df["fp"] + df["fn"]))

import torch
import gc
from tqdm import tqdm

dfEval1 = pd.DataFrame()

indexBERT = ['BERT', 'RoBERTa', 'DistilBERT', 'CamemBERT', 'Albert', 'FlauBERT', 'RobBERT']

train_df1 = pd.DataFrame({"text_cleaned_1": X1_train, "target": y_train})
test_df1 = pd.DataFrame({"text_cleaned_1": X1_test, "target": y_test})

train_df2 = pd.DataFrame({"text_cleaned_2": X2_train, "target": y_train})
test_df2 = pd.DataFrame({"text_cleaned_2": X2_test, "target": y_test})

train_df3 = pd.DataFrame({"text_cleaned_3": X3_train, "target": y_train})
test_df3 = pd.DataFrame({"text_cleaned_3": X3_test, "target": y_test})

N_ITER = 5

gc.collect()
torch.cuda.empty_cache()

from huggingface_hub import notebook_login
notebook_login()

"""**roBERTa**"""

for i in range(N_ITER):
    for idx, (train_df, test_df, clean_type) in enumerate(zip(
        [train_df1, train_df2, train_df3], [test_df1, test_df2, test_df3], ["cleaned1", "cleaned2", "cleaned3"]
    )):
        model1c = ClassificationModel(
            "roberta", "roberta-base",
            use_cuda=True,
            args=train_args
        )
        model1c.train_model(train_df)

        result_name = f"result_roberta_{clean_type}_{i}"  # Her iterasyon için ayrı isim
        result1c, _, _ = model1c.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)
        print(f"✅ {result_name} computed.")

        dfResultsRoBERTa = pd.DataFrame.from_dict(result1c, orient="index").T
        dfResultsRoBERTa.to_csv(f"/content/drive/MyDrive/NLP_Results/results_roberta_{clean_type}_{i}.csv", index=False)

        del model1c
        gc.collect()
        torch.cuda.empty_cache()

from IPython.display import display

# Models and cleaning types
indexBERT = ['BERT', 'RoBERTa', 'DistilBERT', 'Albert']
clean_types = ["cleaned1", "cleaned2", "cleaned3"]

# a list to store all results
all_results = []

# Merge results for 3 cleaning types
for clean_type in clean_types:
    df_list = []

    for model_name in indexBERT:
        model_files = [
            pd.read_csv(f"/content/drive/MyDrive/NLP_Results/results_{model_name.lower()}_{clean_type}_{i}.csv")
            for i in range(N_ITER)
        ]

        # Merge and add metadata
        model_results = pd.concat(model_files, ignore_index=True)
        model_results["Model"] = model_name
        model_results["Cleaning Type"] = clean_type
        df_list.append(model_results)

    # Merge results of all models and save it
    dfResultsModelsTotal = pd.concat(df_list, ignore_index=True)
    final_path = f"/content/drive/MyDrive/NLP_Results/final_results_{clean_type}.csv"
    dfResultsModelsTotal.to_csv(final_path, index=False)
    all_results.append(dfResultsModelsTotal)

    print(f"{clean_type} results are saved: {final_path}")

# Merge all results for 3 cleaning methods
dfResultsModelsTotal = pd.concat(all_results, ignore_index=True)

# Show only key metrics
columns_to_show = ["Model", "Cleaning Type", "accuracy", "f1_score", "auroc", "eval_loss"]
df_sorted = dfResultsModelsTotal[columns_to_show].sort_values(by=["Model", "Cleaning Type"])

# Get mean for each model and cleaning method combination
df_summary = df_sorted.groupby(["Model", "Cleaning Type"]).mean().reset_index()

# apply html styling for bold names
df_summary["Model"] = df_summary["Model"].apply(lambda x: f"**{x}**")

# create an appropriate table style for report
styled_table = df_summary.style.set_properties(**{
    "border": "1px solid black",
    "text-align": "center",
    "font-size": "12pt",
    "font-weight": "bold"
}).set_table_styles([
    {"selector": "thead th", "props": [("background-color", "#2F4F4F"), ("color", "white"), ("font-weight", "bold"), ("text-align", "center")]},
    {"selector": "tbody td", "props": [("border", "1px solid black"), ("text-align", "center")]},
    {"selector": "tbody tr:hover", "props": [("background-color", "#D3D3D3")]}
])

# show results
display(styled_table)

import matplotlib.pyplot as plt
import seaborn as sns

# Metric Type for plotting
metric = "accuracy"

# Create bar graph
plt.figure(figsize=(10, 6))
sns.barplot(data=df_summary, x="Cleaning Type", y=metric, hue="Model")

# Details of graph
plt.title(f"Comparison of Cleaning Methods Based on {metric}")
plt.xlabel("Cleaning Method")
plt.ylabel(metric.capitalize())
plt.legend(title="Model")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.7)

# Show graph
plt.show()

plt.figure(figsize=(10, 6))
sns.lineplot(data=df_summary, x="Cleaning Type", y=metric, hue="Model", marker="o", linewidth=2.5)

# Graph details
plt.title(f"Performance Trend of Cleaning Methods for {metric}")
plt.xlabel("Cleaning Method")
plt.ylabel(metric.capitalize())
plt.legend(title="Model")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.7)

plt.show()

# Convert data to pivot form
df_pivot = df_summary.pivot(index="Model", columns="Cleaning Type", values=metric)

# create heat map
plt.figure(figsize=(8, 6))
sns.heatmap(df_pivot, annot=True, cmap="coolwarm", linewidths=0.5, fmt=".3f")

# graph details
plt.title(f"Performance of Cleaning Methods - {metric}")
plt.xlabel("Cleaning Method")
plt.ylabel("Model")

plt.show()

import sys, gc, torch

gc.collect()
torch.cuda.empty_cache()
print(torch.cuda.memory_summary(device=0, abbreviated=False))

import time
import torch
import gc
import pandas as pd
from simpletransformers.classification import ClassificationModel
from sklearn.metrics import f1_score, accuracy_score

# Function to calculate F1 score
def f1_multiclass(labels, preds):
    return f1_score(labels, preds, average='micro')

# Models
models = {
    "bert": "bert-base-multilingual-cased",
    "roberta": "roberta-base",
    "distilbert": "distilbert-base-cased",
    "albert": "albert-base-v1",
}

# Evaluate model on different cleaning methods
for clean_type, train_df, test_df in zip(
    ["cleaned1", "cleaned2", "cleaned3"],
    [train_df1, train_df2, train_df3],
    [test_df1, test_df2, test_df3]
):
    for model_name, model_path in models.items():
        print(f"Evaluating {model_name} on {clean_type} dataset...")

        model = ClassificationModel(
            model_name, model_path,
            use_cuda=True,
            args=train_args
        )

        # Measure inference time
        start_test = time.time()
        result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)
        end_test = time.time()
        inference_time = end_test - start_test
        result["inference_time"] = inference_time

        # Save results
        result_df = pd.DataFrame([result])
        save_path = f"/content/drive/MyDrive/NLP_Results/results_{model_name}_{clean_type}.csv"
        result_df.to_csv(save_path, index=False)

        print(f"{model_name.upper()} Model Results ({clean_type}) saved: {save_path}")
        print(f"Inference time: {inference_time:.2f} seconds")

        # Save wrong predictions
        wrong_preds_df = pd.DataFrame(wrong_predictions, columns=["Text", "True_Label", "Predicted_Label"])
        wrong_preds_path = f"/content/drive/MyDrive/NLP_Results/wrong_predictions_{model_name}_{clean_type}.csv"
        wrong_preds_df.to_csv(wrong_preds_path, index=False)

        print(f"Wrong Predictions saved: {wrong_preds_path}")

        # Clean memory
        del model
        gc.collect()
        torch.cuda.empty_cache()

gc.collect()
torch.cuda.empty_cache()
print(torch.cuda.memory_summary(device=0, abbreviated=False))